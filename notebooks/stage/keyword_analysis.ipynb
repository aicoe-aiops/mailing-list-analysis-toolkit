{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Keyword Analysis \n",
    "\n",
    "This notebook ingests the preprocessed data from `../interim/text` downloaded by `download_datasets.ipynb` and uses a TF-IDF method to identify the top 10 keywords for each month. This is done by implementing the following procedure: For each month, we train and fit a separate TF-IDF model, then collect the top 10 scoring words for each email and sum their occurrences to identify the top 10 most frequently occurring keywords for each month.     \n",
    "\n",
    "Finally, the data is saved as a single csv file and pushed to remote storage for visualization with Superset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getenv(\"LOCAL_DATA_PATH\", \"../../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;1519862707.18745.0@posteo.de&gt;</td>\n",
       "      <td>Wed, 28 Feb 2018 18:05:07 -0600</td>\n",
       "      <td>['\\nI have an update here:\\n\\nhttps://bodhi.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;b88b4d3b-b8f7-2ea6-ec41-ab572b831717@dustymab...</td>\n",
       "      <td>Wed, 28 Feb 2018 19:43:15 -0500</td>\n",
       "      <td>[\"-----BEGIN PGP SIGNED MESSAGE-----\\nHash: SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;45117c81-43ff-656d-85c3-3cf003bd0d14@fedorapr...</td>\n",
       "      <td>Wed, 28 Feb 2018 20:49:25 -0500</td>\n",
       "      <td>['On 02/28/2018 07:05 PM, mcatanzaro(a)gnome.o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;CAA55FSN-R4oV0os0LihZQTp8aa0NkR9jQPh44subK2+9...</td>\n",
       "      <td>Wed, 28 Feb 2018 21:11:19 -0500</td>\n",
       "      <td>['On 28 February 2018 at 10:03, Nicolas Mailho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p77nrn$t3b$1@blaine.gmane.org&gt;</td>\n",
       "      <td>Thu, 01 Mar 2018 03:19:34 +0100</td>\n",
       "      <td>['Fabio Valentini wrote:\\n&gt; AFAICT, those \"bro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Message-ID  \\\n",
       "0                     <1519862707.18745.0@posteo.de>   \n",
       "1  <b88b4d3b-b8f7-2ea6-ec41-ab572b831717@dustymab...   \n",
       "2  <45117c81-43ff-656d-85c3-3cf003bd0d14@fedorapr...   \n",
       "3  <CAA55FSN-R4oV0os0LihZQTp8aa0NkR9jQPh44subK2+9...   \n",
       "4                    <p77nrn$t3b$1@blaine.gmane.org>   \n",
       "\n",
       "                              Date  \\\n",
       "0  Wed, 28 Feb 2018 18:05:07 -0600   \n",
       "1  Wed, 28 Feb 2018 19:43:15 -0500   \n",
       "2  Wed, 28 Feb 2018 20:49:25 -0500   \n",
       "3  Wed, 28 Feb 2018 21:11:19 -0500   \n",
       "4  Thu, 01 Mar 2018 03:19:34 +0100   \n",
       "\n",
       "                                                Body  \n",
       "0  ['\\nI have an update here:\\n\\nhttps://bodhi.fe...  \n",
       "1  [\"-----BEGIN PGP SIGNED MESSAGE-----\\nHash: SH...  \n",
       "2  ['On 02/28/2018 07:05 PM, mcatanzaro(a)gnome.o...  \n",
       "3  ['On 28 February 2018 at 10:03, Nicolas Mailho...  \n",
       "4  ['Fabio Valentini wrote:\\n> AFAICT, those \"bro...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.load_dataset(f\"{BASE_PATH}/interim/text/\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41997, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "Due to the casual nature of email writing, along with some known useless artifacts present in our textual dataset, we need to clean our data a bit before performing our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_thread(text):\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if len(line) > 0]\n",
    "    lines = [line for line in lines if line[0] != \">\"]\n",
    "    lines = [line for line in lines if line[:3] != \"Re:\"]\n",
    "    lines = [line for line in lines if line[:7] != \"Subject\"]\n",
    "    lines = [line for line in lines if line[:5] != \"From:\"]\n",
    "    lines = [line for line in lines if line[:5] != \"Date:\"]\n",
    "    lines = [line for line in lines if \"BEGIN PGP SIGNED MESSAGE\" not in line]\n",
    "    lines = [line for line in lines if line[:5] != \"Hash:\"]\n",
    "    lines = [line for line in lines if line[:10] != \"Version: G\"]\n",
    "    lines = [line for line in lines if \"wrote:\" not in line]\n",
    "    lines = [line for line in lines if \"wrote :\" not in line]\n",
    "    lines = [line for line in lines if \"writes:\" not in line]\n",
    "    lines = [line for line in lines if line[:7] != \"Am Mit,\"]\n",
    "    lines = [line for line in lines if line[:7] != \"Am Don,\"]\n",
    "    lines = [line for line in lines if line[:7] != \"Am Mon,\"]\n",
    "    lines = [line for line in lines if line[:7] != \"Quoting\"]\n",
    "    lines = [line for line in lines if line[:10] != \"Em Quinta,\"]\n",
    "    lines = [line for line in lines if \"said:\" not in line]\n",
    "    lines = [\n",
    "        line\n",
    "        for line in lines\n",
    "        if re.match(\n",
    "            \".*n (Sun|Mon|Tue|Wed|Thu|Fri|Sat), .. (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec) 20..*\",\n",
    "            line,\n",
    "        )\n",
    "        is None\n",
    "    ]\n",
    "    lines = [\n",
    "        line\n",
    "        for line in lines\n",
    "        if re.match(\n",
    "            (\n",
    "                \".*n (Sunday|Monday|Tuesday|Wednesday|Thursday|Friday|Saturday) ..\"\n",
    "                \" (January|February|March|April|May|June|July|August|September|October|November|December) 20..*\"\n",
    "            ),\n",
    "            line,\n",
    "        )\n",
    "        is None\n",
    "    ]\n",
    "    lines = [\n",
    "        line\n",
    "        for line in lines\n",
    "        if re.match(\n",
    "            \".*n (Sun|Mon|Tue|Wed|Thu|Fri|Sat), (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec) .., 20..*\",\n",
    "            line,\n",
    "        )\n",
    "        is None\n",
    "    ]\n",
    "    lines = [\n",
    "        line\n",
    "        for line in lines\n",
    "        if re.match(\n",
    "            r\".*n (Sun|Mon|Tue|Wed|Thu|Fri|Sat), 20[\\d]{2}-[\\d]{2}-[\\d]{2} at.*\",\n",
    "            line,\n",
    "        )\n",
    "        is None\n",
    "    ]\n",
    "    lines = [line for line in lines if line[-6:] != \"said: \"]\n",
    "    lines = [line for line in lines if line[-8:] != \"babbled:\"]\n",
    "    lines = [line for line in lines if line[-7:] != \"wrot=e:\"]\n",
    "    lines = [line for line in lines if line[-8:] != \"A9crit :\"]\n",
    "    lines = [line for line in lines if line[0] != \"|\"]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# format for CSV, clean special characters, and remove extranous emails\n",
    "def pandas_clean(emails):\n",
    "    emails[\"Body\"].replace(\n",
    "        to_replace=[\n",
    "            r\"\\n\",\n",
    "            \"\\n\",\n",
    "        ],\n",
    "        value=\" \",\n",
    "        regex=True,\n",
    "        inplace=True,\n",
    "    )\n",
    "    emails[\"Body\"].replace(\n",
    "        to_replace=[r\"\\'\", \"'\", \">\", \"<\", \"= \", \"-\", r\"http\\S+\"],\n",
    "        value=\"\",\n",
    "        regex=True,\n",
    "        inplace=True,\n",
    "    )\n",
    "    emails[\"Body\"].replace(\n",
    "        to_replace=[r\"\\\\\\s+\", r\"\\\\s+\", \"=\"], value=\"\", regex=True, inplace=True\n",
    "    )\n",
    "    emails[\"Body\"].replace(\n",
    "        to_replace=[\"   \", \"  \"], value=\" \", regex=True, inplace=True\n",
    "    )\n",
    "    emails[\"Body\"].replace(\n",
    "        to_replace=[\"_\", \"3D\"], value=\"\", regex=True, inplace=True\n",
    "    )\n",
    "    emails[\"Body\"].replace(\n",
    "        to_replace=[\"   \", \"  \"], value=\" \", regex=True, inplace=True\n",
    "    )\n",
    "    emails[\"Body\"].replace(\n",
    "        to_replace=[\"   \", \"  \"], value=\" \", regex=True, inplace=True\n",
    "    )\n",
    "    emails[\"Body\"] = emails[\"Body\"].apply(\n",
    "        lambda x: x.strip().replace(r\"\\n\", \"\")\n",
    "    )\n",
    "\n",
    "    emails.drop(emails.index[emails[\"Body\"] == \"\"], inplace=True)\n",
    "    emails.drop(emails.index[emails[\"Body\"] == \" \"], inplace=True)\n",
    "    emails.dropna(subset=[\"Body\"], inplace=True)\n",
    "\n",
    "    emails = emails.reset_index()\n",
    "    emails.drop(\"index\", axis=1, inplace=True)\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;1519862707.18745.0@posteo.de&gt;</td>\n",
       "      <td>Wed, 28 Feb 2018 18:05:07 -0600</td>\n",
       "      <td>[I have an update here: is blocked due to some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;1519885501.29070.9.camel@fedoraproject.org&gt;</td>\n",
       "      <td>Thu, 01 Mar 2018 01:25:01 -0500</td>\n",
       "      <td>[\"C2A0Following is the list of topics that wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;1519886671.29070.13.camel@fedoraproject.org&gt;</td>\n",
       "      <td>Thu, 01 Mar 2018 01:44:31 -0500</td>\n",
       "      <td>[\"C2A0The Fedora Packaging Committee has some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;1519888291.16369.3.camel@fedoraproject.org&gt;</td>\n",
       "      <td>Thu, 01 Mar 2018 02:11:31 -0500</td>\n",
       "      <td>[\"C2A0The Fedora Packaging Committee has some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;20180301103525.22531.58685@mailman01.phx2.fed...</td>\n",
       "      <td>Thu, 01 Mar 2018 10:35:25 +0000</td>\n",
       "      <td>[Hi,when compiling qarte4.4.0 with this spec f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13862</th>\n",
       "      <td>&lt;20190630045144.22906.88878@mailman01.phx2.fed...</td>\n",
       "      <td>Sun, 30 Jun 2019 04:51:44 +0000</td>\n",
       "      <td>[\"speedtestcli and python3speedtestcli appear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13863</th>\n",
       "      <td>&lt;c94d58e2-e218-8f69-0ff2-a46cd57ab65b@redhat.com&gt;</td>\n",
       "      <td>Sun, 30 Jun 2019 11:46:31 +0200</td>\n",
       "      <td>[Hey,pip and Python packages generally deem 5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13864</th>\n",
       "      <td>&lt;ee3d5633-fd1b-7f71-e173-788c61c9a9e3@gmail.com&gt;</td>\n",
       "      <td>Sun, 30 Jun 2019 05:21:47 -0500</td>\n",
       "      <td>[\"Hi,Does Fedora Silverblue Rawhide not suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13865</th>\n",
       "      <td>&lt;ee5805d4ea36e9b22893b21d2cf41bfda2db6dca.came...</td>\n",
       "      <td>Sun, 30 Jun 2019 08:51:21 -0700</td>\n",
       "      <td>[\"Hi folks! Im proposing we cancel the QA meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>&lt;66883937-a249-059a-fff0-161eeddc6db6@redhat.com&gt;</td>\n",
       "      <td>Sun, 30 Jun 2019 23:51:57 +0200</td>\n",
       "      <td>[Hi All,The work I\\ve been doing to improve su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13867 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Message-ID  \\\n",
       "0                         <1519862707.18745.0@posteo.de>   \n",
       "1           <1519885501.29070.9.camel@fedoraproject.org>   \n",
       "2          <1519886671.29070.13.camel@fedoraproject.org>   \n",
       "3           <1519888291.16369.3.camel@fedoraproject.org>   \n",
       "4      <20180301103525.22531.58685@mailman01.phx2.fed...   \n",
       "...                                                  ...   \n",
       "13862  <20190630045144.22906.88878@mailman01.phx2.fed...   \n",
       "13863  <c94d58e2-e218-8f69-0ff2-a46cd57ab65b@redhat.com>   \n",
       "13864   <ee3d5633-fd1b-7f71-e173-788c61c9a9e3@gmail.com>   \n",
       "13865  <ee5805d4ea36e9b22893b21d2cf41bfda2db6dca.came...   \n",
       "13866  <66883937-a249-059a-fff0-161eeddc6db6@redhat.com>   \n",
       "\n",
       "                                  Date  \\\n",
       "0      Wed, 28 Feb 2018 18:05:07 -0600   \n",
       "1      Thu, 01 Mar 2018 01:25:01 -0500   \n",
       "2      Thu, 01 Mar 2018 01:44:31 -0500   \n",
       "3      Thu, 01 Mar 2018 02:11:31 -0500   \n",
       "4      Thu, 01 Mar 2018 10:35:25 +0000   \n",
       "...                                ...   \n",
       "13862  Sun, 30 Jun 2019 04:51:44 +0000   \n",
       "13863  Sun, 30 Jun 2019 11:46:31 +0200   \n",
       "13864  Sun, 30 Jun 2019 05:21:47 -0500   \n",
       "13865  Sun, 30 Jun 2019 08:51:21 -0700   \n",
       "13866  Sun, 30 Jun 2019 23:51:57 +0200   \n",
       "\n",
       "                                                    Body  \n",
       "0      [I have an update here: is blocked due to some...  \n",
       "1      [\"C2A0Following is the list of topics that wil...  \n",
       "2      [\"C2A0The Fedora Packaging Committee has some ...  \n",
       "3      [\"C2A0The Fedora Packaging Committee has some ...  \n",
       "4      [Hi,when compiling qarte4.4.0 with this spec f...  \n",
       "...                                                  ...  \n",
       "13862  [\"speedtestcli and python3speedtestcli appear ...  \n",
       "13863  [Hey,pip and Python packages generally deem 5....  \n",
       "13864  [\"Hi,Does Fedora Silverblue Rawhide not suppor...  \n",
       "13865  [\"Hi folks! Im proposing we cancel the QA meet...  \n",
       "13866  [Hi All,The work I\\ve been doing to improve su...  \n",
       "\n",
       "[13867 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = df.copy()\n",
    "clean[\"Body\"] = clean[\"Body\"].apply(strip_thread)\n",
    "clean = pandas_clean(clean)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;20180101220004.0E97560A400C@fedocal02.phx2.fe...</td>\n",
       "      <td>2018-01-01 22:00:04+00:00</td>\n",
       "      <td>[Dear all,You are kindly invited to the meetin...</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;20180101220004.0632660A400B@fedocal02.phx2.fe...</td>\n",
       "      <td>2018-01-01 22:00:04+00:00</td>\n",
       "      <td>[Dear all,You are kindly invited to the meetin...</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;20180101221314.GA52721@rawhide-composer.phx2....</td>\n",
       "      <td>2018-01-01 22:13:15+00:00</td>\n",
       "      <td>[OLD: FedoraRawhide20171231.n.0NEW: FedoraRawh...</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;20180101233509.D734E60478E3@bastion01.phx2.fe...</td>\n",
       "      <td>2018-01-01 23:35:09+00:00</td>\n",
       "      <td>[Missing expected images:Server dvd i386Workst...</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;66075732-52f6-2eb8-de1b-d89ec18244db@redhat.com&gt;</td>\n",
       "      <td>2018-01-02 10:26:51+01:00</td>\n",
       "      <td>[\"Could you please drop the dependency on GCC ...</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Message-ID  \\\n",
       "0  <20180101220004.0E97560A400C@fedocal02.phx2.fe...   \n",
       "1  <20180101220004.0632660A400B@fedocal02.phx2.fe...   \n",
       "2  <20180101221314.GA52721@rawhide-composer.phx2....   \n",
       "3  <20180101233509.D734E60478E3@bastion01.phx2.fe...   \n",
       "4  <66075732-52f6-2eb8-de1b-d89ec18244db@redhat.com>   \n",
       "\n",
       "                        Date  \\\n",
       "0  2018-01-01 22:00:04+00:00   \n",
       "1  2018-01-01 22:00:04+00:00   \n",
       "2  2018-01-01 22:13:15+00:00   \n",
       "3  2018-01-01 23:35:09+00:00   \n",
       "4  2018-01-02 10:26:51+01:00   \n",
       "\n",
       "                                                Body       Chunk  \n",
       "0  [Dear all,You are kindly invited to the meetin...  2018-01-01  \n",
       "1  [Dear all,You are kindly invited to the meetin...  2018-01-01  \n",
       "2  [OLD: FedoraRawhide20171231.n.0NEW: FedoraRawh...  2018-01-01  \n",
       "3  [Missing expected images:Server dvd i386Workst...  2018-01-01  \n",
       "4  [\"Could you please drop the dependency on GCC ...  2018-01-01  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean[\"Date\"] = clean[\"Date\"].apply(lambda x: pd.to_datetime(x))\n",
    "clean[\"Chunk\"] = clean[\"Date\"].apply(\n",
    "    lambda x: datetime.date(x.year, x.month, 1)\n",
    ")\n",
    "clean = clean.sort_values(by=\"Date\")\n",
    "clean.reset_index(inplace=True, drop=True)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13862</th>\n",
       "      <td>&lt;20201130211635.21006.77071@mailman01.iad2.fed...</td>\n",
       "      <td>2020-11-30 21:16:35+00:00</td>\n",
       "      <td>[Hello. I want to buy myself Dell XPS 13 9310 ...</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13863</th>\n",
       "      <td>&lt;28998e59-9857-8c3d-548f-47d6642d3789@redhat.com&gt;</td>\n",
       "      <td>2020-11-30 23:00:32+01:00</td>\n",
       "      <td>[Hi guys,not sure whether I missed something, ...</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13864</th>\n",
       "      <td>&lt;e1fcf02c-43d0-00e1-6b6a-0eed22468ca0@redhat.com&gt;</td>\n",
       "      <td>2020-11-30 14:06:04-08:00</td>\n",
       "      <td>[Hi,As part of the f34 change request[1] for r...</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13865</th>\n",
       "      <td>&lt;637e6814-bc05-4713-6226-7192a437df46@redhat.com&gt;</td>\n",
       "      <td>2020-11-30 23:23:18+01:00</td>\n",
       "      <td>[Dne 30. 11. 20 v 19:29 Rudolf Kastl napsal(a)...</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>&lt;1fb0c88e-79fa-ce05-8c77-5a0e8c95a0a8@redhat.com&gt;</td>\n",
       "      <td>2020-11-30 23:31:39+01:00</td>\n",
       "      <td>[Dne 30. 11. 20 v 23:06 Tom Stellard napsal(a)...</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Message-ID  \\\n",
       "13862  <20201130211635.21006.77071@mailman01.iad2.fed...   \n",
       "13863  <28998e59-9857-8c3d-548f-47d6642d3789@redhat.com>   \n",
       "13864  <e1fcf02c-43d0-00e1-6b6a-0eed22468ca0@redhat.com>   \n",
       "13865  <637e6814-bc05-4713-6226-7192a437df46@redhat.com>   \n",
       "13866  <1fb0c88e-79fa-ce05-8c77-5a0e8c95a0a8@redhat.com>   \n",
       "\n",
       "                            Date  \\\n",
       "13862  2020-11-30 21:16:35+00:00   \n",
       "13863  2020-11-30 23:00:32+01:00   \n",
       "13864  2020-11-30 14:06:04-08:00   \n",
       "13865  2020-11-30 23:23:18+01:00   \n",
       "13866  2020-11-30 23:31:39+01:00   \n",
       "\n",
       "                                                    Body       Chunk  \n",
       "13862  [Hello. I want to buy myself Dell XPS 13 9310 ...  2020-11-01  \n",
       "13863  [Hi guys,not sure whether I missed something, ...  2020-11-01  \n",
       "13864  [Hi,As part of the f34 change request[1] for r...  2020-11-01  \n",
       "13865  [Dne 30. 11. 20 v 19:29 Rudolf Kastl napsal(a)...  2020-11-01  \n",
       "13866  [Dne 30. 11. 20 v 23:06 Tom Stellard napsal(a)...  2020-11-01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single month example \n",
    "\n",
    "Here we will prototype our method for identifying top N key words for a single month, to ensure it works properly before applying it to the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = clean[clean.Chunk == datetime.date(2020, 11, 1)].Body\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 37733)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cloudbaseqcow2qcow2',\n",
       " 'ttest',\n",
       " 'aarch64',\n",
       " 'x8664',\n",
       " 'uefiurl',\n",
       " 'fedoracloud3320201031',\n",
       " 'soft',\n",
       " '712248',\n",
       " '712249',\n",
       " '712250']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "Document = []\n",
    "for i, j in enumerate(X[0].toarray()[0]):\n",
    "    if j > 0:\n",
    "        Document.append((i, j))\n",
    "\n",
    "top_10 = sorted(Document, key=lambda x: x[1], reverse=True)[0:10]\n",
    "top_10_keys = [x[0] for x in top_10]\n",
    "[feature_array[i] for i in top_10_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13427    [No missing expected images.Soft failed openQA...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[No missing expected images.Soft failed openQA tests: 1/7 (x8664), 1/7 (aarch64)(Tests completed, but using a workaround for a known bug)Old soft failures (same test soft failed in FedoraCloud3320201031.0):ID: 712253\\\\tTest: x8664 CloudBaseqcow2qcow2 cloudautocloudURL: 712261\\\\tTest: aarch64 CloudBaseqcow2qcow2 cloudautocloud(a)uefiURL: openQA tests: 6/7 (x8664), 6/7 (aarch64)New passes (same test not passed in FedoraCloud3320201031.0):ID: 712248\\\\tTest: x8664 CloudBaseqcow2qcow2 baserebootunmountURL: 712249\\\\tTest: x8664 CloudBaseqcow2qcow2 basesystemloggingURL: 712250\\\\tTest: x8664 CloudBaseqcow2qcow2 baseupdatecliURL: 712251\\\\tTest: x8664 CloudBaseqcow2qcow2 baseservicemanipulationURL: 712252\\\\tTest: x8664 CloudBaseqcow2qcow2 baseservicesstartURL: 712254\\\\tTest: x8664 CloudBaseqcow2qcow2 baseselinuxURL: 712255\\\\tTest: aarch64 CloudBaseqcow2qcow2 basesystemlogging(a)uefiURL: 712256\\\\tTest: aarch64 CloudBaseqcow2qcow2 baserebootunmount(a)uefiURL: 712257\\\\tTest: aarch64 CloudBaseqcow2qcow2 baseservicesstart(a)uefiURL: 712258\\\\tTest: aarch64 CloudBaseqcow2qcow2 baseupdatecli(a)uefiURL: 712259\\\\tTest: aarch64 CloudBaseqcow2qcow2 baseservicemanipulation(a)uefiURL: 712260\\\\tTest: aarch64 CloudBaseqcow2qcow2 baseselinux(a)uefiURL: Mail generated by checkcompose:'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[corpus[0:1].index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks out key words are reasonable given the email in question above.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run full analysis entire dataset \n",
    "\n",
    "Now that we are confident our approach works, we will break it up into manageable functions and apply it to each months dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_monthly_tfidf(corpus):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    x = vectorizer.fit_transform(corpus)\n",
    "    return x, vectorizer\n",
    "\n",
    "\n",
    "def top_words_per_email(email_vector, feature_array, top_words=10):\n",
    "    document = []\n",
    "    for i, j in enumerate(email_vector.toarray()[0]):\n",
    "        if j > 0:\n",
    "            document.append((i, j))\n",
    "    top_n = sorted(document, key=lambda x: x[1], reverse=True)[0:top_words]\n",
    "    top_n_keys = [x[0] for x in top_n]\n",
    "    top_n_words = [feature_array[i] for i in top_n_keys]\n",
    "    return top_n_words\n",
    "\n",
    "\n",
    "def get_monthly_keywords(corpus, chunk):\n",
    "    x, vectorizer = train_monthly_tfidf(corpus)\n",
    "    feature_array = np.array(vectorizer.get_feature_names())\n",
    "    keywords = []\n",
    "    for i in range(x.shape[0]):\n",
    "        keywords.extend(top_words_per_email(x[i], feature_array))\n",
    "\n",
    "    keywords = Counter(keywords).most_common(10)\n",
    "    keywords = pd.DataFrame(keywords, columns=[\"word\", \"count\"])\n",
    "    keywords[\"month\"] = chunk\n",
    "\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01\n",
      "2018-02-01\n",
      "2018-03-01\n",
      "2018-04-01\n",
      "2018-05-01\n",
      "2018-06-01\n",
      "2018-07-01\n",
      "2018-08-01\n",
      "2018-09-01\n",
      "2018-10-01\n",
      "2018-11-01\n",
      "2018-12-01\n",
      "2019-01-01\n",
      "2019-02-01\n",
      "2019-03-01\n",
      "2019-04-01\n",
      "2019-05-01\n",
      "2019-06-01\n",
      "2019-07-01\n",
      "2019-08-01\n",
      "2019-09-01\n",
      "2019-10-01\n",
      "2019-11-01\n",
      "2019-12-01\n",
      "2020-01-01\n",
      "2020-02-01\n",
      "2020-03-01\n",
      "2020-04-01\n",
      "2020-05-01\n",
      "2020-06-01\n",
      "2020-07-01\n",
      "2020-08-01\n",
      "2020-09-01\n",
      "2020-10-01\n",
      "2020-11-01\n"
     ]
    }
   ],
   "source": [
    "# For each document collect the top 10 words, then sum the top 10 for each month.\n",
    "\n",
    "months = clean.Chunk.unique()\n",
    "monthly_keywords = pd.DataFrame([], columns=[\"word\", \"count\", \"month\"])\n",
    "\n",
    "for month in months:\n",
    "    corpus = clean[clean.Chunk == month].Body\n",
    "    monthly_keywords = monthly_keywords.append(\n",
    "        get_monthly_keywords(corpus, month), ignore_index=True\n",
    "    )\n",
    "    print(month)\n",
    "\n",
    "monthly_keywords = pd.DataFrame(monthly_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_keywords = monthly_keywords.reset_index().set_index(\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_keywords = monthly_keywords.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fc28</th>\n",
       "      <td>32</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>31</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8664</th>\n",
       "      <td>27</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc9kaxy</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudbaseqcow2qcow2</th>\n",
       "      <td>56</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft</th>\n",
       "      <td>55</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>39</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uefiurl</th>\n",
       "      <td>36</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package</th>\n",
       "      <td>31</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       month\n",
       "word                                 \n",
       "fc28                   32  2018-01-01\n",
       "test                   31  2018-01-01\n",
       "x8664                  27  2018-01-01\n",
       "pc9kaxy                26  2018-01-01\n",
       "change                 26  2018-01-01\n",
       "...                   ...         ...\n",
       "cloudbaseqcow2qcow2    56  2020-11-01\n",
       "soft                   55  2020-11-01\n",
       "test                   39  2020-11-01\n",
       "uefiurl                36  2020-11-01\n",
       "package                31  2020-11-01\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload results to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files = ((monthly_keywords, f\"{BASE_PATH}/processed/keywords.csv\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"{BASE_PATH}/processed\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_keywords.to_csv(new_files[0][1], header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"RUN_IN_AUTOMATION\"):\n",
    "    utils.upload_files(\n",
    "        (f, f\"processed/{Path(f).stem}/keywords.csv\") for _, f in new_files\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "devenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
