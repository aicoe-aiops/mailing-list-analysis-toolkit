{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Keyword Analysis \n",
    "\n",
    "This notebook ingests the preprocessed data from `../interim/text` downloaded by `download_datasets.ipynb` and uses a TF-IDF method to identify the top 10 keywords for each month. This is done by implementing the following procedure: For each month, we train and fit a separate TF-IDF model, then collect the top 10 scoring words for each email and sum their occurrences to identify the top 10 most frequently occurring keywords for each month.     \n",
    "\n",
    "Finally, the data is saved as a single csv file and pushed to remote storage for visualization with Superset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "import gc\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")\n",
    "sys.path.append(\"../..\")\n",
    "from src import utils  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getenv(\"LOCAL_DATA_PATH\", \"../../data\")\n",
    "\n",
    "LAST_MONTH_DATE = datetime.datetime.now().replace(day=1) - datetime.timedelta(\n",
    "    days=1\n",
    ")\n",
    "year = LAST_MONTH_DATE.year\n",
    "month = LAST_MONTH_DATE.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"RUN_IN_AUTOMATION\"):\n",
    "    df = pd.read_csv(\n",
    "        f\"{BASE_PATH}/interim/text/fedora-devel-{year}-{month}.mbox.csv\"\n",
    "    )\n",
    "    df.head()\n",
    "\n",
    "else:\n",
    "    df = utils.load_dataset(f\"{BASE_PATH}/interim/text/\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3962, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Text Preprocessing\n",
    "\n",
    "Due to the casual nature of email writing, along with some known useless artifacts present in our textual dataset, we need to clean our data a bit before performing our analysis.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;e0c38165-50de-dfb8-77ce-596489e2ecbf@compton.nu&gt;</td>\n",
       "      <td>2020-12-01 00:06:04+00:00</td>\n",
       "      <td>Do we really have to go through this all again...</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;CAB-QmhR9rhdwBfW+cGvOW0wdsJMbGhuk9_9Mj43A5_GY...</td>\n",
       "      <td>2020-12-01 01:12:20+01:00</td>\n",
       "      <td>On Tue, Dec 1, 2020 at 1:06 AM Tom Hughes via ...</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;1f51986b-c5b6-b073-d908-a8c713e9c9ad@redhat.com&gt;</td>\n",
       "      <td>2020-12-01 01:58:12+01:00</td>\n",
       "      <td>ntirely. That was exactly my reasoning. Miro H...</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;d59cdf62-19a9-62d8-dab0-a2b73f0489e8@redhat.com&gt;</td>\n",
       "      <td>2020-11-30 17:05:38-08:00</td>\n",
       "      <td>We never came to a conclusion on this, because...</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;32b36717-bec7-1747-d7ea-55627c1779dc@redhat.com&gt;</td>\n",
       "      <td>2020-11-30 17:37:05-08:00</td>\n",
       "      <td>e: False positive because it matches the regex...</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Message-ID  \\\n",
       "0  <e0c38165-50de-dfb8-77ce-596489e2ecbf@compton.nu>   \n",
       "1  <CAB-QmhR9rhdwBfW+cGvOW0wdsJMbGhuk9_9Mj43A5_GY...   \n",
       "2  <1f51986b-c5b6-b073-d908-a8c713e9c9ad@redhat.com>   \n",
       "3  <d59cdf62-19a9-62d8-dab0-a2b73f0489e8@redhat.com>   \n",
       "4  <32b36717-bec7-1747-d7ea-55627c1779dc@redhat.com>   \n",
       "\n",
       "                        Date  \\\n",
       "0  2020-12-01 00:06:04+00:00   \n",
       "1  2020-12-01 01:12:20+01:00   \n",
       "2  2020-12-01 01:58:12+01:00   \n",
       "3  2020-11-30 17:05:38-08:00   \n",
       "4  2020-11-30 17:37:05-08:00   \n",
       "\n",
       "                                                Body       Chunk  \n",
       "0  Do we really have to go through this all again...  2020-12-01  \n",
       "1  On Tue, Dec 1, 2020 at 1:06 AM Tom Hughes via ...  2020-12-01  \n",
       "2  ntirely. That was exactly my reasoning. Miro H...  2020-12-01  \n",
       "3  We never came to a conclusion on this, because...  2020-11-01  \n",
       "4  e: False positive because it matches the regex...  2020-11-01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x))\n",
    "df[\"Chunk\"] = df[\"Date\"].apply(lambda x: datetime.date(x.year, x.month, 1))\n",
    "df = df.sort_values(by=\"Date\")\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Body</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>&lt;346ef226-3317-c310-d80c-283e4cc7dc2d@redhat.com&gt;</td>\n",
       "      <td>2021-02-27 20:30:45+01:00</td>\n",
       "      <td>Hi Benjamin, Ray, I noticed this problem while...</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>&lt;CAA_UwzK-njEiGSvq6FfGWteCz93Cm-Uk-KGLdC4f=Bq1...</td>\n",
       "      <td>2021-02-27 14:56:02-05:00</td>\n",
       "      <td>ah i think we need to pull in Ray y. l, .org</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>&lt;8dee2ff2-e118-bdb2-5d77-20ca82759727@gmail.com&gt;</td>\n",
       "      <td>2021-02-27 20:59:59+01:00</td>\n",
       "      <td>Hi, I am trying to test some Renoir s2idle pat...</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>&lt;CAA_Uwz+nM0n85OyaAd6=55_ANw4yefwAqJ3k40e91Yui...</td>\n",
       "      <td>2021-02-27 15:16:43-05:00</td>\n",
       "      <td>Hi, seems like this is already in updates. you...</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>&lt;4199adc3-49c8-4d3d-d768-84327df177fa@gmail.com&gt;</td>\n",
       "      <td>2021-02-27 18:56:52-05:00</td>\n",
       "      <td>The assimp license field for version 5.0.1 has...</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message-ID  \\\n",
       "3957  <346ef226-3317-c310-d80c-283e4cc7dc2d@redhat.com>   \n",
       "3958  <CAA_UwzK-njEiGSvq6FfGWteCz93Cm-Uk-KGLdC4f=Bq1...   \n",
       "3959   <8dee2ff2-e118-bdb2-5d77-20ca82759727@gmail.com>   \n",
       "3960  <CAA_Uwz+nM0n85OyaAd6=55_ANw4yefwAqJ3k40e91Yui...   \n",
       "3961   <4199adc3-49c8-4d3d-d768-84327df177fa@gmail.com>   \n",
       "\n",
       "                           Date  \\\n",
       "3957  2021-02-27 20:30:45+01:00   \n",
       "3958  2021-02-27 14:56:02-05:00   \n",
       "3959  2021-02-27 20:59:59+01:00   \n",
       "3960  2021-02-27 15:16:43-05:00   \n",
       "3961  2021-02-27 18:56:52-05:00   \n",
       "\n",
       "                                                   Body       Chunk  \n",
       "3957  Hi Benjamin, Ray, I noticed this problem while...  2021-02-01  \n",
       "3958       ah i think we need to pull in Ray y. l, .org  2021-02-01  \n",
       "3959  Hi, I am trying to test some Renoir s2idle pat...  2021-02-01  \n",
       "3960  Hi, seems like this is already in updates. you...  2021-02-01  \n",
       "3961  The assimp license field for version 5.0.1 has...  2021-02-01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single month example \n",
    "\n",
    "Here we will prototype our method for identifying top N key words for a single month, to ensure it works properly before applying it to the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 71)\n"
     ]
    }
   ],
   "source": [
    "if not os.getenv(\"RUN_IN_AUTOMATION\"):\n",
    "    corpus = df[df.Chunk == datetime.date(2020, 11, 1)].Body\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'was', 'be', 'came', 'cmake', 'conclusion', 'going', 'never', 'on', 'or']\n",
      "\n",
      "We never came to a conclusion on this, because it was unclear whether make was going to be a weak or strong dependency of cmake. Tom\n"
     ]
    }
   ],
   "source": [
    "if not os.getenv(\"RUN_IN_AUTOMATION\"):\n",
    "    feature_array = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "    Document = []\n",
    "    for i, j in enumerate(X[0].toarray()[0]):\n",
    "        if j > 0:\n",
    "            Document.append((i, j))\n",
    "\n",
    "    top_10 = sorted(Document, key=lambda x: x[1], reverse=True)[0:10]\n",
    "    top_10_keys = [x[0] for x in top_10]\n",
    "    print([feature_array[i] for i in top_10_keys], end=\"\\n\\n\")\n",
    "    print(corpus[corpus[0:1].index[0]])\n",
    "    del feature_array\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks out key words are reasonable given the email in question above.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run full analysis on entire dataset \n",
    "\n",
    "Now that we are confident our approach works, we will break it up into manageable functions and apply it to each months dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_monthly_tfidf(corpus):\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    x = vectorizer.fit_transform(corpus)\n",
    "    return x, vectorizer\n",
    "\n",
    "\n",
    "def top_words_per_email(email_vector, feature_array, top_words=10):\n",
    "    document = []\n",
    "    for i, j in enumerate(email_vector.toarray()[0]):\n",
    "        if j > 0:\n",
    "            document.append((i, j))\n",
    "    top_n = sorted(document, key=lambda x: x[1], reverse=True)[0:top_words]\n",
    "    top_n_keys = [x[0] for x in top_n]\n",
    "    top_n_words = [feature_array[i] for i in top_n_keys]\n",
    "    return top_n_words\n",
    "\n",
    "\n",
    "def get_monthly_keywords(corpus, chunk):\n",
    "    x, vectorizer = train_monthly_tfidf(corpus)\n",
    "    feature_array = np.array(vectorizer.get_feature_names())\n",
    "    keywords = []\n",
    "    for i in range(x.shape[0]):\n",
    "        keywords.extend(top_words_per_email(x[i], feature_array))\n",
    "\n",
    "    keywords = Counter(keywords).most_common(10)\n",
    "    keywords = pd.DataFrame(keywords, columns=[\"word\", \"count\"])\n",
    "    keywords[\"month\"] = chunk\n",
    "    del feature_array\n",
    "    gc.collect()\n",
    "\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = Path(f\"{BASE_PATH}/processed/keywords/\")\n",
    "dataset_base_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-01\n",
      "2020-11-01\n",
      "2021-01-01\n",
      "2021-02-01\n"
     ]
    }
   ],
   "source": [
    "# For each document collect the top 10 words, then sum the top 10 for each month.\n",
    "\n",
    "months = df.Chunk.unique()\n",
    "new_files = []\n",
    "\n",
    "for month in months:\n",
    "    corpus = df[df.Chunk == month].Body\n",
    "    monthly_keywords = get_monthly_keywords(corpus, month)\n",
    "    monthly_keywords = monthly_keywords.reset_index().set_index(\"word\")\n",
    "    monthly_keywords = monthly_keywords.drop(\"index\", axis=1)\n",
    "    monthly_keywords.to_csv(\n",
    "        f\"{BASE_PATH}/processed/keywords/keywords-{month}.csv\", header=False\n",
    "    )\n",
    "    new_files.append(f\"{BASE_PATH}/processed/keywords/keywords-{month}.csv\")\n",
    "    print(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aarch64</th>\n",
       "      <td>116</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8664</th>\n",
       "      <td>115</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ttest</th>\n",
       "      <td>94</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tests</th>\n",
       "      <td>77</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed</th>\n",
       "      <td>64</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudbaseqcow2qcow2</th>\n",
       "      <td>56</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft</th>\n",
       "      <td>55</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>39</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uefiurl</th>\n",
       "      <td>36</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package</th>\n",
       "      <td>31</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count       month\n",
       "word                                  \n",
       "aarch64                116  2020-11-01\n",
       "x8664                  115  2020-11-01\n",
       "ttest                   94  2020-11-01\n",
       "tests                   77  2020-11-01\n",
       "failed                  64  2020-11-01\n",
       "cloudbaseqcow2qcow2     56  2020-11-01\n",
       "soft                    55  2020-11-01\n",
       "test                    39  2020-11-01\n",
       "uefiurl                 36  2020-11-01\n",
       "package                 31  2020-11-01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload results to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"RUN_IN_AUTOMATION\"):\n",
    "    utils.upload_files(\n",
    "        (f, f\"processed/keywords/{Path(f).stem}.csv\") for f in new_files\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
